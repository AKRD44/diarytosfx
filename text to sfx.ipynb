{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text to sfx\n",
    "\n",
    "The goal is to take a string input (max 4 lines) and return reasonable sound effects to go with the text. \n",
    "\n",
    "For my first attempt I will go with something fairly simple.\n",
    "\n",
    "I have a whole bunch of sound effect files, each with a descriptive title. I convert those titles into word2vec vectors. I then do the same for the input text. Then I find do a cosine similarity amongst the vectors to find which ones are most similar to the input text. \n",
    "\n",
    "I also want 2 sound effect files to play, so one more thing I need to make sure of is that these two sound effect files aren't too similar to each other. I can make sure the files are different enough by clustering the most similar vectors and looking for the top two recommendations from different clusters. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import sklearn\n",
    "from sklearn.cluster import AgglomerativeClustering,DBSCAN\n",
    "\n",
    "from my_text_process_scripts import *\n",
    "import json\n",
    "\n",
    "data_folder=\"../data/\"\n",
    "tags_folder=\"../sound_effects/tags\"\n",
    "sound_folder=\"../sound_effects/sounds/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# diary entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "input_text=\"\"\"I just moved to New York, so it’s been a little tough meeting people. It seems like everyone already has their own group of friends. So I’m trying to become more of a ‘yes’ person and do things I normally wouldn’t do. Like I came to the park today instead of sitting at home. And I went to my first hockey game yesterday. And I joined a dodgeball team on Thursday nights. Dodgeball is a lot more pressure than I thought it would be. I try to hang back and not throw the ball, but then usually I’m the last one and everyone is aiming at me. The only consolation is knowing that it’s going to be over in two seconds. And after the game we all go to the bar. Our team name is ‘We Throw Things and Drink.’” \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How it works for sound effect retrieval\n",
    "\n",
    "\n",
    "I have a dictionary of sound effect files and their w2v vectors. I was hoping to just convert the input text a vector and then see to which sfx vector it was most similar to.\n",
    "\n",
    "One thing I've noticed though is that nouns are very important. \n",
    "\n",
    "case 1: \n",
    "Guy goes into the bar with friends to watch sports. \n",
    "\n",
    "sfx with high similarity is [\"baby\",\"happy\",\"friendly\"]\n",
    "two of those words sort of match with the setting, but baby definitely does not. \n",
    "so how shall I deal with this?\n",
    "\n",
    "need to determine which one is a noun. \n",
    "use spacy for the input text\n",
    "would spacy work for the flags? not in sentence form. \n",
    "\n",
    "\n",
    "Then I need to weigh it. \n",
    "can find the similarity word for word, would give you a normalized score between 0 and 1. Which you could use to weigh the rest.\n",
    "\n",
    "Compare flag noun vector with the summed up input vector. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "wav_to_vec_dict=load_obj(\"wav_to_vec_dict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading the word2vec model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "\n",
    "my_w2v=KeyedVectors.load_word2vec_format(os.path.join(data_folder,'GoogleNews-vectors-normed2.bin'),binary=True, encoding='utf-8', unicode_errors='ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turning my w2v vectors into a numpy matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename_dict = dict(enumerate(wav_to_vec_dict.keys()))\n",
    "\n",
    "sent_dict = dict(enumerate(wav_to_vec_dict.values()))\n",
    "\n",
    "sent_matrix=np.array(list(sent_dict.values()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace any nan values with the mean in the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_to_mean(sent_matrix):\n",
    "\n",
    "    col_mean = np.nanmean(sent_matrix, axis=0)\n",
    "    inds = np.where(np.isnan(sent_matrix))\n",
    "    sent_matrix[inds] = np.take(col_mean, inds[1])\n",
    "    \n",
    "    return sent_matrix\n",
    "\n",
    "sent_matrix=nan_to_mean(sent_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vecSim(vec1,vec2):\n",
    "    answer=sklearn.metrics.pairwise.cosine_similarity(vec1.reshape(1,-1),vec2.reshape(1,-1))\n",
    "    \n",
    "    return answer[0][0]\n",
    "\n",
    "\n",
    "def wordlist2vec(words_list,word_vectors):\n",
    "    final_results=[]\n",
    "    for word in words_list:\n",
    "        try:\n",
    "            if len(final_results)==0:\n",
    "\n",
    "                final_results=word_vectors[word]\n",
    "            else:\n",
    "\n",
    "                final_results=final_results+word_vectors[word]\n",
    "        except:\n",
    "            print(\"word not found: \"+word)\n",
    "            pass\n",
    "        \n",
    "    return final_results\n",
    "\n",
    "\n",
    "tokenized_resulting_string=tokenize_process(input_text)\n",
    "\n",
    "\n",
    "words_in_voc=[]\n",
    "#CHECKING FOR WHAT'S IN THE DICTIONARY\n",
    "for each_word in tokenized_resulting_string:\n",
    "\n",
    "    if each_word in my_w2v.vocab:\n",
    "\n",
    "        words_in_voc.append(each_word)\n",
    "\n",
    "if len(words_in_voc)!=0:\n",
    "\n",
    "    vectorized_input_text=wordlist2vec(words_in_voc,my_w2v)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_similarities=np.apply_along_axis(vecSim, 1, sent_matrix,vec2=vectorized_input_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_sent_similarities=sent_similarities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.653071  , 0.6517482 , 0.6375183 , 0.6016448 , 0.5872398 ,\n",
       "       0.57675105, 0.56047845, 0.5595844 , 0.545179  , 0.53961396,\n",
       "       0.52695936, 0.5266143 , 0.5234463 , 0.5234463 , 0.5220766 ,\n",
       "       0.5147978 , 0.51438665, 0.51360714, 0.5087781 , 0.5073549 ,\n",
       "       0.50308156, 0.5001439 , 0.49987566, 0.49346298, 0.4928645 ,\n",
       "       0.49256867, 0.4925185 , 0.4921887 , 0.4921033 , 0.49114478],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep the top 30 for now\n",
    "# in the future I might need some kind of minimum similarity \n",
    "\n",
    "#either just keep a certain number\n",
    "best_match_sort=np.argsort(adj_sent_similarities)[::-1][:30]\n",
    "adj_sent_similarities[best_match_sort]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#find out how well all sound effect titles compare to all others.\n",
    "sfx_similarities=sklearn.metrics.pairwise.cosine_similarity(sent_matrix[best_match_sort],sent_matrix[best_match_sort])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "The reason for the clustering is because I have a lot of similar sound effects (example: walking.wav and man_walking.wav)\n",
    "and seeing as I don't want to just retrieve two similar sound effects. By clustering them, there's a better chance that sound effects from different clusters are actually different. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['House_home\\\\25_Match_Struck_spark_start_fire.wav',\n",
       " 'America\\\\sports_crowd_excited_fans_soccer_football_outside_score_happy.wav']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = sfx_similarities\n",
    "clustering = AgglomerativeClustering().fit_predict(X)\n",
    "\n",
    "unique_clusters=np.unique(clustering)\n",
    "\n",
    "#how many sfx I want in my video\n",
    "nber_sfx=2\n",
    "\n",
    "indexes=[]\n",
    "for each_cluster in unique_clusters:\n",
    "    \n",
    "    indexes.append(np.where(clustering==each_cluster)[0][0])\n",
    "    \n",
    "#retrieving indexes for files\n",
    "sfx_index=best_match_sort[indexes]\n",
    "#retrieving sfx file names\n",
    "sfx_files_to_play=[filename_dict[x] for x in sfx_index]\n",
    "\n",
    "sfx_files_to_play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
